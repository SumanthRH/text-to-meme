{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "470f1f65-5712-42a8-bcf0-2a560ee2baae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import math, statistics, time\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "# import torch_xla\n",
    "# import torch_xla.core.xla_model as xm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# HF token\n",
    "token = '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'\n",
    "from huggingface_hub import HfApi, HfFolder\n",
    "api=HfApi()\n",
    "folder=HfFolder()\n",
    "api.set_access_token(token)\n",
    "folder.save_token(token)\n",
    "\n",
    "with open('./models/data/training_label.pkl', 'rb') as f:\n",
    "    labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a70fc2b4-f09d-4837-bc84-06e537f15bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in meme dict dataset: dict_keys(['label_uuid_dic', 'uuid_label_dic', 'uuid_caption_dic', 'uuid_image_path_dic'])\n",
      "Number of uuids: 300\n"
     ]
    }
   ],
   "source": [
    "# load meme dataset\n",
    "meme_dict = None\n",
    "with open('./meme_900k_cleaned_data.pkl', 'rb') as f:\n",
    "    meme_dict = pickle.load(f)\n",
    "print(\"Keys in meme dict dataset:\", meme_dict.keys())\n",
    "print(\"Number of uuids:\", len(meme_dict['uuid_label_dic']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cf16c42-aad7-4f3c-8bcd-f21947364fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "def clean_and_unify_caption(caption):\n",
    "    return caption[0].strip()+'; '+caption[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f7c563e-bdf0-4123-9b45-66697b758f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180000 22500 22500\n"
     ]
    }
   ],
   "source": [
    "# create pandas dataframe\n",
    "training_uuids = labels.keys()\n",
    "temp_arr = []\n",
    "for uuid in training_uuids:\n",
    "    for caption in meme_dict['uuid_caption_dic'][uuid]:\n",
    "        temp_arr.append([uuid, clean_and_unify_caption(caption)])\n",
    "df = pd.DataFrame(temp_arr, columns=['category', 'text'])\n",
    "\n",
    "# split dataset\n",
    "np.random.seed(42)\n",
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), \n",
    "                                     [int(.8*len(df)), int(.9*len(df))])\n",
    "\n",
    "print(len(df_train),len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f52f5c92-5336-409a-a4cd-9858046062a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cac8b42-b955-4fe7-a788-cd6d89018b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.labels = [labels[label] for label in df['category']]\n",
    "        self.texts = [text for text in df['text']]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dd9eab1-4fc8-4b01-abb5-398810cb5951",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(df_train)\n",
    "val_dataset = Dataset(df_val)\n",
    "test_dataset = Dataset(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fc3017fa-ea58-4b41-b88d-15236a5c1969",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceBertDataloader:\n",
    "    def __init__(self, dataset, tokenizer, batch_size):\n",
    "        self.labels = np.array(dataset.labels)\n",
    "        self.texts = np.array(dataset.texts)\n",
    "        self.batch_size = batch_size\n",
    "        self.num_data_points = len(self.labels)\n",
    "        self.num_meme_keys = len(set(self.labels))\n",
    "        self.datapoints_per_meme = self.num_data_points//self.num_meme_keys\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        # create mapping from meme id to list of texts for sampling +ve/-ve examples\n",
    "        self.meme_id_text_dic = defaultdict(list)\n",
    "        for meme_id, text in tqdm(zip(self.labels, self.texts)):\n",
    "            self.meme_id_text_dic[meme_id].append(text)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(len(self.labels)/self.batch_size + 1)\n",
    "    \n",
    "    def samplePositives(self, true_label, true_text):\n",
    "        count = 0\n",
    "        positive_examples = []\n",
    "        while count<2:\n",
    "            random_text = np.random.choice(self.meme_id_text_dic[true_label])\n",
    "            if random_text!=true_text:\n",
    "                count+=1\n",
    "                positive_examples.append(random_text)\n",
    "        return positive_examples\n",
    "    \n",
    "    def sampleNegatives(self, true_label, true_text):\n",
    "        count = 0\n",
    "        negative_examples = []\n",
    "        while count<2:\n",
    "            random_meme_id = np.random.randint(0, self.num_meme_keys)\n",
    "            random_text = np.random.choice(self.meme_id_text_dic[random_meme_id])\n",
    "            if random_meme_id!=true_label and random_text!=true_text:\n",
    "                count+=1\n",
    "                negative_examples.append(random_text)\n",
    "        return negative_examples\n",
    "    \n",
    "    def __iter__(self):\n",
    "        # shuffle data\n",
    "        indices = np.arange(self.num_data_points)\n",
    "        np.random.shuffle(indices)\n",
    "        X = self.texts[indices]\n",
    "        y = self.labels[indices]\n",
    "        \n",
    "        for i in range(0, self.num_data_points, self.batch_size):\n",
    "            X_batch = X[i:i+self.batch_size]\n",
    "            y_batch = y[i:i+self.batch_size]\n",
    "            \n",
    "            X_final_batch = []\n",
    "            y_final_batch = []\n",
    "            for i in range(len(X_batch)):\n",
    "                positive_examples = self.samplePositives(y_batch[i], X_batch[i])\n",
    "                negative_examples = self.sampleNegatives(y_batch[i], X_batch[i])\n",
    "                for example in positive_examples:\n",
    "                    X_final_batch.append(tokenizer([X_batch[i], example],padding='max_length', max_length = 50, truncation=True, return_tensors=\"pt\"))\n",
    "                    y_final_batch.append(1)\n",
    "                for example in negative_examples:\n",
    "                    X_final_batch.append(tokenizer([X_batch[i], example],padding='max_length', max_length = 50, truncation=True, return_tensors=\"pt\"))\n",
    "                    y_final_batch.append(0)\n",
    "            \n",
    "            yield X_final_batch, torch.tensor(y_final_batch, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5e1c16e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a811363c5cdf44ea812e2ec939db334e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "405f57cfb4574462afc67c33f6a00ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba3e3789dda406cbb21d15b860e0403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loader = SentenceBertDataloader(train_dataset, tokenizer, 32)\n",
    "val_loader = SentenceBertDataloader(val_dataset, tokenizer, 32)\n",
    "test_loader = SentenceBertDataloader(test_dataset, tokenizer, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "add93e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /home/ykhandelwal/.cache/torch/sentence_transformers/bert-base-uncased. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at /home/ykhandelwal/.cache/torch/sentence_transformers/bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('bert-base-uncased')\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc85f4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5736d3b79a47fbba238d45b3031e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0017cea4cef45aebe20942408416937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/5626 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (128) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_objectives\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/yash/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:721\u001b[0m, in \u001b[0;36mSentenceTransformer.fit\u001b[0;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit)\u001b[0m\n\u001b[1;32m    719\u001b[0m     skip_scheduler \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mget_scale() \u001b[38;5;241m!=\u001b[39m scale_before_step\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 721\u001b[0m     loss_value \u001b[38;5;241m=\u001b[39m \u001b[43mloss_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    722\u001b[0m     loss_value\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    723\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(loss_model\u001b[38;5;241m.\u001b[39mparameters(), max_grad_norm)\n",
      "File \u001b[0;32m~/.conda/envs/yash/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/yash/lib/python3.10/site-packages/sentence_transformers/losses/CosineSimilarityLoss.py:41\u001b[0m, in \u001b[0;36mCosineSimilarityLoss.forward\u001b[0;34m(self, sentence_features, labels)\u001b[0m\n\u001b[1;32m     39\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(sentence_feature)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence_embedding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m sentence_feature \u001b[38;5;129;01min\u001b[39;00m sentence_features]\n\u001b[1;32m     40\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcos_score_transformation(torch\u001b[38;5;241m.\u001b[39mcosine_similarity(embeddings[\u001b[38;5;241m0\u001b[39m], embeddings[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_fct\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/yash/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/yash/lib/python3.10/site-packages/torch/nn/modules/loss.py:530\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/yash/lib/python3.10/site-packages/torch/nn/functional.py:3279\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3277\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3279\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[0;32m~/.conda/envs/yash/lib/python3.10/site-packages/torch/functional.py:73\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (128) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "model.fit(train_objectives=[(train_loader, train_loss)],epochs=1, warmup_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69c5de7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_dataloader:\n",
    "    temp = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adc429d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "494937ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'input_ids': tensor([[ 101, 2178, 3940,  102,    0],\n",
       "           [ 101, 2026, 2034, 6251,  102]]),\n",
       "   'token_type_ids': tensor([[0, 0, 0, 0, 0],\n",
       "           [0, 0, 0, 0, 0]]),\n",
       "   'attention_mask': tensor([[1, 1, 1, 1, 0],\n",
       "           [1, 1, 1, 1, 1]])},\n",
       "  {'input_ids': tensor([[  101, 15142,  6251,   102,     0],\n",
       "           [  101,  2026,  2117,  6251,   102]]),\n",
       "   'token_type_ids': tensor([[0, 0, 0, 0, 0],\n",
       "           [0, 0, 0, 0, 0]]),\n",
       "   'attention_mask': tensor([[1, 1, 1, 1, 0],\n",
       "           [1, 1, 1, 1, 1]])}],\n",
       " tensor([0.3000, 0.8000]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "025b362e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57cd5d7a941469fb0884fb0ba9d8777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f379f3b654c04f0ab99c5f7a1bac3293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f393b56a42df4f8d946bb309e217ebf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c1965eadc64a2b8d9aded2d440616b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56c5015a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my', 'first', 'sentence', 'my', 'second', 'sentence']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(['My first sentence', 'My second sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4581db65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2026, 2034, 6251,  102],\n",
       "        [ 101, 2026, 2117, 6251,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(['My first sentence', 'My second sentence'],return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e34ea742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'input_ids': tensor([[ 101, 2178, 3940,  102,    0],\n",
       "           [ 101, 2026, 2034, 6251,  102]]),\n",
       "   'token_type_ids': tensor([[0, 0, 0, 0, 0],\n",
       "           [0, 0, 0, 0, 0]]),\n",
       "   'attention_mask': tensor([[1, 1, 1, 1, 0],\n",
       "           [1, 1, 1, 1, 1]])},\n",
       "  {'input_ids': tensor([[  101, 15142,  6251,   102,     0],\n",
       "           [  101,  2026,  2117,  6251,   102]]),\n",
       "   'token_type_ids': tensor([[0, 0, 0, 0, 0],\n",
       "           [0, 0, 0, 0, 0]]),\n",
       "   'attention_mask': tensor([[1, 1, 1, 1, 0],\n",
       "           [1, 1, 1, 1, 1]])}],\n",
       " tensor([0.3000, 0.8000]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8cd29a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yash",
   "language": "python",
   "name": "yash"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
