{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d02a0010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import string\n",
    "import regex as re\n",
    "from collections import defaultdict\n",
    "import os, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a267e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reading dank learning captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f92f546e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   'y u no - meme generator users y u no give me more upvotes?\\n',\n",
      "    'y u no - steve jobs y u no respawn?!\\n',\n",
      "    'y u no - commercial y u no same volume as show!?\\n',\n",
      "    'y u no - kony y u no take justin bieber \\n',\n",
      "    'y u no - victoria y u no tell us your secret?!\\n',\n",
      "    'y u no - ted y u no tell us how you met their mother\\n',\n",
      "    'y u no - google y u no let me finish typing?\\n',\n",
      "    'y u no - pink floyd y u no need no education?\\n',\n",
      "    'y u no - universal remote y u no work on universe?\\n',\n",
      "    'y u no - girl looking for prince charming  y u no check friend zone?!\\n']\n",
      "[   'Y U No - meme generator users y u no give me more upvotes?\\n',\n",
      "    'Y U No - steve jobs y u no respawn?!\\n',\n",
      "    'Y U No - commercial y u no same volume as show!?\\n',\n",
      "    'Y U No - KONY Y u no take justin bieber \\n',\n",
      "    'Y U No - Victoria y u no tell us your secret?!\\n',\n",
      "    'Y U No - TED y u no tell us how you met their mother\\n',\n",
      "    'Y U No - Google Y U NO LET ME FINISH TYPING?\\n',\n",
      "    'Y U No - pink floyd y u no need no education?\\n',\n",
      "    'Y U No - universal remote y u no work on universe?\\n',\n",
      "    'Y U No - Girl looking for prince charming  Y u no check friend zone?!\\n']\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "with open('./Dank-Learning/im2txt/CaptionsClean.txt') as f:\n",
    "    dank_captions_clean = f.readlines()\n",
    "with open('./Dank-Learning/im2txt/Captions.txt') as f:\n",
    "    dank_captions_unclean = f.readlines()\n",
    "    \n",
    "pp.pprint(dank_captions_clean[:10])\n",
    "pp.pprint(dank_captions_unclean[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ac1f895",
   "metadata": {},
   "outputs": [],
   "source": [
    "## utility code to download memes900k dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a07d4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gdown\n",
    "\n",
    "# url = 'https://drive.google.com/uc?id=1j6YG3skamxA1-mdogC1kRjugFuOkHt_A'\n",
    "# gdown.download(url, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85a24290",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reading memes 900k captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbb955db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   'Y U No\\t1145\\tcommercial <sep> y u no same volume as show!?\\n',\n",
      "    'Y U No\\t984\\tVictoria <sep> y u no tell us your secret?!\\n',\n",
      "    'Y U No\\t908\\tKONY <sep> Y u no take justin bieber\\n',\n",
      "    'Y U No\\t866\\tTED <sep> y u no tell us how you met their mother\\n',\n",
      "    'Y U No\\t823\\tGoogle <sep> Y U NO LET ME FINISH TYPING?\\n',\n",
      "    'Y U No\\t727\\tuniversal remote <sep> y u no work on universe?\\n',\n",
      "    'Y U No\\t707\\tpink floyd <sep> y u no need no education?\\n',\n",
      "    'Y U No\\t699\\tINTERNET <sep> y u nO LET ME STUDY\\n',\n",
      "    'Y U No\\t697\\tGirl looking for prince charming <sep> Y u no check friend '\n",
      "    'zone?!\\n',\n",
      "    'Y U No\\t633\\ti held the door <sep> y u no say thank you\\n']\n"
     ]
    }
   ],
   "source": [
    "with open('./memes900k/captions.txt') as f:\n",
    "    data_captions_unclean = f.readlines()\n",
    "pp.pprint(data_captions_unclean[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d2e5799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_captions(data):\n",
    "    def clean_single_caption(caption):\n",
    "        try:\n",
    "            label, meme_id, raw_text = caption.split(\"\\t\")\n",
    "        except:\n",
    "            print(\"invalid input\")\n",
    "            return None\n",
    "        \n",
    "        # preprocess meme_id\n",
    "        meme_id = meme_id.strip().strip(\"\\n\").lower()\n",
    "        \n",
    "        # preprocess label to match with image name\n",
    "        # remove - and _ from punctuation\n",
    "        punctuation = '!\"#$%&\\'()*+,./:;<=>?@[\\\\]^`{|}~'     \n",
    "        label = label.strip().strip(\"\\n\").lower()\n",
    "        label = label.translate(str.maketrans('', '', punctuation)).replace(\"ñ\", \"\")\n",
    "        splits = re.split(\"\\s-\\s|\\s+|-|_\", label)\n",
    "        label = \"-\".join(splits)\n",
    "        \n",
    "        # preprocess caption lines\n",
    "        caption_lines = raw_text.split(\"<sep>\")\n",
    "        caption_lines = [line.strip().strip(\"\\n\").lower() for line in caption_lines]\n",
    "        \n",
    "        return label, meme_id, caption_lines\n",
    "    \n",
    "    cleaned_data = []\n",
    "    for raw_caption in data:\n",
    "        cleaned_data.append(clean_single_caption(raw_caption))\n",
    "    return cleaned_data\n",
    "\n",
    "cleaned_data = clean_captions(data_captions_unclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe96edb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!ONLY DO THIS ONCE!!!!!\n",
    "# # generate label to meme_uuid map\n",
    "# import uuid\n",
    "# unique_labels = list(set([x[0] for x in cleaned_data]))\n",
    "# label_uuid_dic = {x: str(uuid.uuid4()) for x in unique_labels}\n",
    "\n",
    "# # generate meme_uuid to label reverse map\n",
    "# uuid_label_dic = {v:k for k,v in label_uuid_dic.items()}\n",
    "\n",
    "# # generate meme_uuid to list of captions map\n",
    "# uuid_caption_dic = defaultdict(list)\n",
    "# for label, meme_id, caption  in cleaned_data:\n",
    "#     uuid_caption_dic[label_uuid_dic[label]].append(caption)\n",
    "\n",
    "# # generate meme_uuid to image path map\n",
    "# image_paths = [f for f in glob.glob(\"./memes900k/images/*.jpg\")]\n",
    "# uuid_image_path_dic = {}\n",
    "# for path in image_paths:\n",
    "#     label = path.split(\"/\")[-1].split(\".\")[0]\n",
    "#     if label in label_uuid_dic:\n",
    "#         uuid_image_path_dic[label_uuid_dic[label]]=path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "994c21d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !!!!!ONLY DO THIS ONCE!!!!!\n",
    "# data = {\n",
    "#     'label_uuid_dic': label_uuid_dic,\n",
    "#     'uuid_label_dic': uuid_label_dic,\n",
    "#     'uuid_caption_dic': uuid_caption_dic, \n",
    "#     'uuid_image_path_dic': uuid_image_path_dic\n",
    "# }\n",
    "\n",
    "# with open('meme_900k_cleaned_data.pkl', 'wb') as f:\n",
    "#     pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98bc58d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load clean data from pickle\n",
    "with open('meme_900k_cleaned_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3fe6f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create user files \n",
    "# uuids = list(data['uuid_label_dic'].keys())\n",
    "# with open('tim.pkl', 'wb') as f:\n",
    "#     pickle.dump(uuids[:100], f)\n",
    "# with open('sumanth.pkl', 'wb') as f:\n",
    "#     pickle.dump(uuids[100:200], f)\n",
    "# with open('yash.pkl', 'wb') as f:\n",
    "#     pickle.dump(uuids[200:], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c97940f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_captions(data):\n",
    "    def clean_single_caption(caption):\n",
    "        try:\n",
    "            label, meme_id, raw_text = caption.split(\"\\t\")\n",
    "        except:\n",
    "            print(\"invalid input\")\n",
    "            return None\n",
    "        \n",
    "        # preprocess meme_id\n",
    "        meme_id = meme_id.strip().strip(\"\\n\").lower()\n",
    "        \n",
    "        # preprocess label to match with image name\n",
    "        # remove - and _ from punctuation\n",
    "        punctuation = '!\"#$%&\\'()*+,./:;<=>?@[\\\\]^`{|}~'     \n",
    "        label = label.strip().strip(\"\\n\").lower()\n",
    "        label = label.translate(str.maketrans('', '', punctuation)).replace(\"ñ\", \"\")\n",
    "        splits = re.split(\"\\s-\\s|\\s+|-|_\", label)\n",
    "        label = \"-\".join(splits)\n",
    "        \n",
    "        # preprocess caption lines\n",
    "        caption_lines = raw_text.split(\"<sep>\")\n",
    "        caption_lines = [line.strip().strip(\"\\n\") for line in caption_lines]\n",
    "        \n",
    "        return label, meme_id, caption_lines\n",
    "    \n",
    "    cleaned_data = []\n",
    "    for raw_caption in data:\n",
    "        cleaned_data.append(clean_single_caption(raw_caption))\n",
    "    return cleaned_data\n",
    "\n",
    "cleaned_data = clean_captions(data_captions_unclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f452c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "uuid_caption_cased_dic = defaultdict(list)\n",
    "for label, meme_id, caption  in cleaned_data:\n",
    "    uuid_caption_cased_dic[data['label_uuid_dic'][label]].append(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40224ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['uuid_caption_cased_dic']=uuid_caption_cased_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c495e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('meme_900k_cleaned_data_v2.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c62838",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meme",
   "language": "python",
   "name": "meme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
